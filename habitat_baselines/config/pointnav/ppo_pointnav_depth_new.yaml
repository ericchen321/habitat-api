# Evaluate with the depth agent.
# Modified from ppo_pointnav.yaml
# Note:  Hyperparameters have been changed slightly from
# the paper to allow for things to easily run on 1 GPU

# Changed task config to pointnav.yaml
BASE_TASK_CONFIG_PATH: "configs/tasks/pointnav.yaml"
TRAINER_NAME: "ppo"
ENV_NAME: "NavRLEnv"
SIMULATOR_GPU_ID: 0
TORCH_GPU_ID: 0
# Can be uncommented to generate videos.
VIDEO_OPTION: ["disk", "tensorboard"]
TENSORBOARD_DIR: "tb"
VIDEO_DIR: "video_dir"
# Changed to evaluate on 50 episodes
TEST_EPISODE_COUNT: 50
EVAL_CKPT_PATH_DIR: "data/checkpoint_depth_new"
# This was 6 for mp3d and 8 for gibson in the paper
NUM_PROCESSES: 1
# Note:  To train the an RGB only model,
# you may need to use 8 processes with 4 mini batches,
# If so, the number of updates should be cut in half
SENSORS: ["DEPTH_SENSOR"]
CHECKPOINT_FOLDER: "data/checkpoint_depth_new"
NUM_UPDATES: 270000
LOG_INTERVAL: 10
CHECKPOINT_INTERVAL: 50

RL:
  PPO:
    # ppo params
    clip_param: 0.1
    ppo_epoch: 4
    # This was 4 in the paper
    num_mini_batch: 2
    value_loss_coef: 0.5
    entropy_coef: 0.01
    lr: 2.5e-4
    eps: 1e-5
    max_grad_norm: 0.5
    num_steps: 128
    hidden_size: 512
    use_gae: True
    gamma: 0.99
    tau: 0.95
    use_linear_clip_decay: True
    use_linear_lr_decay: True
    reward_window_size: 50
